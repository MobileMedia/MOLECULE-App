<!--#####################################################################
LAKER Version 1.0 – http://www.lakercompendium.com##########################################################################################################################################This is a dossier file.###############################################################################################################################################################################################################-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns:csi="http://www.massimocorner.com/libraries/csi/"
  xmlns="http://www.w3.org/1999/xhtml" lang="de">
  <head>
    <meta content="text/html; charset=UTF-8" http-equiv="content-type">
    <!--############################################################################
META information #######################################################################################################################################-->
    <meta charset="utf-8">
    <!--Prevent pinch to zoom on iOS devices-->
    <meta content="width=device-width; initial-scale=1.0;
      maximum-scale=1.0; user-scalable=no;" name="viewport">
    <!--Allow saving as a web app on the home screen on iOS Devices (doesn't apply in Baker)-->
    <meta content="yes" name="apple-mobile-web-app-capable">
    <!--If the page is saved as a web app, the statusbar will be black-translucent (doesn't apply in Baker)-->
    <meta content="black-translucent"
      name="apple-mobile-web-app-status-bar-style">
    <!--Prevent phone number detection on iOS devices-->
    <meta content="telephone=no" name="format-detection">
    <!--Title. The content of the title is displayed on the loading screen on iOS devices-->
    <title>Augmented Reality for Learning</title>
    <!--############################################################################
Stylesheets ############################################################################################################################################--><!--Loading the main style sheet-->
    <link type="text/css" rel="stylesheet" href="styles/styles.css">
    <!--Loading the dossier specific css-->
    <link type="text/css" rel="stylesheet" href="styles/dossiers/05.css">
    <!--############################################################################
Javascripts ############################################################################################################################################-->
    <script type="text/javascript" src="js/Hyphenator.js"></script>
    <script type="text/javascript" src="js/jquery-1.5.min.js"></script>
    <script src="js/tmt_core.js" type="text/javascript"></script>
    <script src="js/tmt_net.js" type="text/javascript"></script>
    <script src="js/tmt_csi.js" type="text/javascript"></script>
    <!--Card Flip Effect-->
    <script src="js/jquery-css-transform.js" type="text/javascript"></script>
    <script src="js/rotate3Di.js" type="text/javascript"></script>
    <!--Audio Player-->
    <script src="js/jquery.jplayer.min.js" type="text/javascript"></script>
    <!--Mandatory JavaScripts (Uncomment if not used to speed up performance)
<script type="text/javascript" src="js/jquery.jplayer.min.js"></script><script src="js/jquery.touchSwipe-1.2.1.js" type="text/javascript"></script>-->
  </head>
  <body>
    <!--############################################################################
"Table of content" in navigation bar ###################################################################################################################-->
    <div class="nav-bar">
      <div class="nav-bar-container"> <a class="nav-button toc"
          href="#Inhaltsverzeichnis">
          <div class="toc-label">Inhaltsverzeichnis</div>
          <div class="toc-list">
            <!--Include "Table of content" from external file--> </div>
          <!--Div toc-list--> </a> </div>
      <!--Div nav-bar-container--> </div>
    <!--Div nav-bar-->
    <!--############################################################################
End "Table of content" in navigation bar ###############################################################################################################--><!--############################################################################
Start dossier navigation in navigation bar #############################################################################################################--><!--Include the small logo and the cover link-->
    <!--Link to the next dossier--> <a class="nav-button next"
      href="06.html">
      <div class="nav-button-text">Next Dossier</div>
    </a>
    <!--Link to the previous dossier--> <a class="nav-button prev"
      href="04.html">
      <div class="nav-button-text">Previous Dossier</div>
    </a>
    <!--Implementing the Dossier-Number-->
    <div class="dossier-number" id="dossier-number">
      <p>05</p>
    </div>
    <!--Navigation bar edges-->
    <!--############################################################################
End dossier navigation in navigation bar ###############################################################################################################--><!--Enable text hyphenation with Hyphenator.js-->
    <div class="hyphenate">
      <!--############################################################################
Start content ##########################################################################################################################################--><!--Dossier start image-->
      <div class="dossier-start-bg">
        <!--(if you want to place something on top of the picture, place it here-->
      </div>
      <!-- Div dossier-start-bg-->
      <!--Arrow which indicates the start of the text-->
      <div class="dossier-headline-arrow"><img
          src="images/dossier-headline-arrow.png"></div>
      <!--"content-element" ensures, that content is placed within the right margins-->
      <div class="content-element">
        <!--Starting Headline-->
        <div class="starting-headline">
          <h1>Augmented Reality for Learning<br>
          </h1>
        </div>
        <!--Div starting headline--> </div>
      <!--Div content element-->
      <!--"content-element" ensures, that content is placed within the right margins-->
      <div class="content-element">
        <div class="large-column float-left">
          <p id="aui_3_2_0_1910">Until recently, augmented reality
            applications were mostly available for powerful workstations
            and high power ultra-mobile personal computers. Adopting
            augmented reality applications on mobile smartphones made
            mobile AR one of the hype topics in 2010 and enabled mobile
            AR experiences in real world settings for the everyday
            smartphone user. Beside the broad pickup by developers and
            end users in the field of tourism and cultural heritage
            applications also several applications focused on education.
            In the following paper we will give an overview of the
            development of mobile AR and it’s applications in the field
            of education. Based on different HCI patterns of AR we will
            also introduce a set of educational patterns identified in
            the analyzed applications and we think are effective
            patterns of using AR for education. </p>
          <p>In their description of the history of mobile AR Wagner et
            AL. (2009) describe the technical developments of AR in that
            context also identify important technical components of
            mobile AR systems </p>
          <div class="starting-headline">
            <h2>Background on Augmented Reality<br>
            </h2>
          </div>
          <p> In the early days of mobile learning research and
            development very much focus has been given to the topic of
            content-delivery and the question how learning content can
            be delivered and altered for smaller screens and portable
            computers. This very device-centric view of mobile learning
            has been changed through the <br>
          </p>
          <p>Situated cognition suggests that learning is naturally tied
            to authentic activity, context and culture (Brown, Collins,
            &amp; Duguid, 1989). Situated learning is referred to as
            learning that takes place in the same context as it is
            applied (Lave &amp; Wenger, 1991).<br>
          </p>
          <ul id="aui_3_2_0_1943">
            <li> Head Mounted Display Systems, camera phones, and
              hand-held projectors </li>
            <li> Sensor systems in mobile devices as gyroscopes, GPS,
              electronic compass, cameras, microphone, as also indoor
              location tracking systems </li>
            <li> Multi-user AR visualization of real time augmented
              reality interaction </li>
            <li> Wireless networking protocols and standards </li>
            <li> Mobile Phones with computational power to do real time
              visualization of 3D objects and overlays as also
              registration and tracking on a standalone device </li>
            <li> Tagging technologies and tracking technologies with six
              degrees of freedom, multi-marker tracking, and hybrid
              tracking systems </li>
            <li> Linking of location-based AR information in
              storytelling and gaming approaches </li>
            <li id="aui_3_2_0_1941"> Flexible layer based AR browsers
              with integration of social media </li>
          </ul>
          <br>
          <p>Milgram and Kishino (Milgram and Kishino,1994) describe
            augmented reality as a continuum “relating purely virtual
            environments to purely real environments”. Whilst they
            describe two different types of AR displays as Head-mounted
            display and monitor based AR displays for mobile AR systems
            new forms of interaction have been identified and will be
            illustrated in the following section. </p>
          <p>Rice (2009) describes AR as follows: “When I talk about AR,
            I try to expand the definition a little bit. Usually, when
            you talk to someone about augmented reality, the first thing
            that comes to mind is overlaying 3D graphics on a video
            stream. I think though, that it should more properly be any
            media that is specific to your location and the context of
            what you are doing (or want to do)…augmenting or enhancing
            your specific reality.” </p>
          <p id="aui_3_2_0_1957">This definition gives a broader
            perspective on augmented reality. Context as defined in
            research to context-aware systems enables augmented reality
            applications to filter information and present information
            overlays relative to the user context (Zimmermann et al,
            2005, Zimmermann et al, 2007). Information in context can
            filtered according to location, direction, focused object,
            time period or learner’s personal interests. Augmented
            reality browsers on mobile smartphones support filtering
            dependent on the sensors available on the mobile device or
            remotely usable services. </p>
        </div>
        <!--Main content-->
        <!--Div large-column float-left--> <br>
        <div class="full-column">
          <h2>Interaction patterns for learning<br>
          </h2>
          <p>Lamantia (2009) describes several forms of HCI patterns of
            mobile AR, which are head-up display, tricorder, holochess,
            and x-ray vision. These interaction design patterns are the
            underlying structures that form mobile AR experiences we
            will use these also to analyze educational AR applications.<br>
          </p>
          <h3 style="font-weight: bold;">Head-up Display (HUD)</h3>
          <p>Head-Up displays (HUD) project information in the visual
            field of the user and were so far mainly used for navigation
            or additional information necessary in the course of action.
            A HUD is the oldest AR interaction pattern and was
            introduced in the 50s. Using a Head-Up Display in the
            cockpit of a fighter-jet, pilots can read information
            without having to move their eyes to a special instrument
            panel. The main characteristics of this interaction pattern
            are: </p>
          <ul>
            <li>
              <p> <small>A user does not take his eyes from the
                  environment to an instrument panel to move. </small></p>
            </li>
            <li>
              <p><small> Information is integrated with the visual field
                  of the user and is synchronized with the movement of
                  the head. </small></p>
            </li>
            <li>
              <p><small> A HUD is typically an integrated system. Where
                  many AR tools rely on external devices, a HUD
                  typically been integrated into an existing device (eg
                  a helmet, a flight or car). </small></p>
            </li>
          </ul>
          <p id="aui_3_2_0_11001">HUD Applications can project
            information on senses other than vision. An audio HUD AR
            system can inform the user of the environment using a
            headset. The LISTEN project (Eckel, 2001) immersed the user
            in 3d audio scenes synchronized with the movements of the
            user, one of the most challenging problems hereby is the
            synchronization of the audio rendering with the physical
            movement of the user. With newer smartphone devices first
            apps also enable mobile phone users outdoors to experience
            audio augmented reality. This is as an example of a HUD
            pattern as it concerns one integrated system. The user is
            also not limited in his interaction possibilities and can
            freely move both head and hands.<br>
          </p>
          <h3 style="font-weight: bold;">Tricoder</h3>
          <p>The Tricorder was introduced in Star Trek science-fiction
            television series<a class="external"
              href="http://en.wikipedia.org/wiki/Tricorder%29.">.</a> It
            is a mobile device that can scan an environment and next
            provides information about that environment. For example,
            after landing on a new planet, the Tricorder was pointed in
            a certain direction and would then present a detailed
            examination of living things in that direction. The Tricoder
            interaction pattern provides the user with information about
            his surroundings and the objects in that environment. A key
            characteristic of this pattern is that the Tricorder is an
            external device. With this external device (e.g. a
            smartphone) the user waves in the direction of interest.
            This pattern builds on an experience in the real world and
            allows the user via augmented reality get additional
            information about its environment. The main characteristics
            of this interaction pattern are: </p>
          <ul id="aui_3_2_0_12073">
            <li> Provides information about an existing environment. </li>
            <li> Is realized through an external device such as a
              smartphone. This distinguishes this pattern of HUD that is
              integrated. A Tricorder introduces interaction
              constraints, which makes it different from a HUD. A user
              needs at least one hand to utilize the Tricorder and thus
              constraints a user’s movement. The Tricorder pattern is
              very important for mobile devices. Most of today’s mobile
              AR applications build on this pattern to display points of
              interest. </li>
            <li id="aui_3_2_0_12063"> In contrast the decoupling of the
              AR display from the users viewpoint also enables different
              perspectives on presented content and explicit selection
              of perspective by the user. Nevertheless this type of use
              is also closely related to the holochess pattern. </li>
          </ul>
          <br>
          <h3><span style="font-weight: bold;">Holochess</span></h3>
          <p>Holochess is the name of the chess game in Star Wars. The
            holochess interaction pattern places virtual objects in the
            real world. These virtual artifacts that are positioned in
            the real world can often interact with one another or can
            interact with objects in the real world. Although mobile AR
            applications have properties of both holochess and
            tricorder, the most important difference is that in
            holochess the virtual object is the object of interest,
            while with tricorder the object serves as an enrichment of
            what the user is looking at. The Holochess patterns can be
            realized with stationary and mobile devices, current
            approaches based on automatic scanning of tags on a table
            can enable direct manipulation of physical objects by the
            users, recent research has shown the efficiency of these
            approaches in vocational training approaches (Do-Lenh et AL,
            2009). </p>
          <h3><span style="font-weight: bold;">X-Ray vision</span></h3>
          <p>In the X-ray vision interaction pattern basically surfaces
            can be looked trough or underlying structures can be
            visualized. On the one hand this can be realized in
            combination with different patterns as tricorder or head-up
            display on the other hand it extends these patterns as the
            augmentation is in most cases based on high precision
            registration. Most application nowadays can be found in the
            medical domain.<br>
          </p>
          <h2
id="section-Augmented+Reality+for+Learning-EducationalPatternsForARBasedLearningSupport">Educational




            patterns for AR based learning support</h2>
          <p>Augmented reality can be applied in various educational
            domains. It can help mobile learners to gain a deeper
            understanding, experience embedded learning content in real
            world overlays, or explore content driven by their current
            context. Most prominent examples support exploration of the
            physical environment with different topics of interest, e.g.
            history, arts, technology, biology, astronomy and others, or
            by enriching artifacts in the physical environment with AR
            techniques. In general AR technically is divided in marker
            less and marker based AR to register digital content for
            real world orientation and placement. This section describes
            a number of educational patterns that are related to the
            interaction patterns discussed earlier. As a simple guide
            the patterns get more complex in the sense of the sensor
            registration that is needed to align and synchronize the
            digital augmentation with the real world. </p>
          <h3 style="font-weight: bold;"
            id="section-Augmented+Reality+for+Learning-Dynamic3DObjects">Dynamic




            3D Objects</h3>
          <p> Several examples in the literature only use the power of
            dynamic displays embedded in mobile devices or with
            stationary screens to visualize 3D objects to illustrate the
            relation between 2D objects and 3D objects or relevant 3D
            concepts (Hagbi et AL, 2009). Martin-Gutierrez et AL (2010)
            used augmented reality visualization for training of
            engineering students on spatial engineering tasks. According
            to Dede (2009) in general AR approaches enable multiple
            perspectives on 3D objects more immersive and situated
            perception of complex spatial shapes. Schmalstieg found that
            an AR system for math and geometry education encouraged
            experimentation of students and improved spatial skills
            (Schmalstieg et AL, 2007). </p>
          <h3 style="font-weight: bold;"
            id="section-Augmented+Reality+for+Learning-AugmentedBooks">Augmented




            books</h3>
          <p> Augmented objects are the simplest form of relating real
            world objects and digital augmentations in principle these
            can be done by manual identification of objects and number
            codes. With camera based phones using visual codes are the
            most popular approach. In principle there are two
            possibilities for displaying the augmentation: a) with a
            mobile device identifying the augmented object the mobile
            device can be used to show the augmentation to the user, b)
            with stationary devices the users can use tags and take hold
            them in front of the camera of a stationary display with
            camera tag tracking and display the augmentation of the
            object tagged. </p>
          <p>Via the integration of markers in books different
            augmentation can be achieved and applications for more
            immersive book experiences or illustration of 2D static
            media with dynamic 3D media can be achieved. Dias (2009)
            identified several effects when using augmented book
            approaches, as enhanced perceived values of learning
            material, educational illustration and better understanding
            of text material. </p>
          <p> </p>
          <h3 style="font-weight: bold;"
            id="section-Augmented+Reality+for+Learning-SensorBasedLayers">Sensor-based




            Layers</h3>
          <p> Sensor based layers extend the perceivable information of
            users based on sensor information. Either the sensor
            information is embedded in the viewpoint of the user or the
            sensor information is used to filter available information
            as geo-tagged information databases. In location based
            information layers the current user location and direction
            is taken to filter information objects and present maps or
            camera overlays with selected information. Most popular
            approaches are based on augmented reality browsers as layar.
            Nowadays with mobile devices mostly this is implemented with
            tricorder interaction patterns. From the educational
            background this is strongly related to the inquiry-based
            approaches to learning support. </p>
          <h3 style="font-weight: bold;"
            id="section-Augmented+Reality+for+Learning-RealWorldObjectScanners">Real




            World Object Scanner</h3>
          <p> Either with marker based technologies or based on other
            sensor information several applications label real world
            objects, prominent examples are the illustration of mountain
            peaks, buildings, or astronomical phenomena. A
            differentiation can be made based on the type of information
            that is displayed for a learner either simple labeling or
            other meta-information can be presented to learn about
            non-visible characteristics or attributed of real-world
            objects. </p>
          <h3 style="font-weight: bold;"
id="section-Augmented+Reality+for+Learning-InstructionalARForRWOManipulation">Instructional




            AR for RWO Manipulation</h3>
          <p> Quite fine granular registration of real world overlays is
            needed for complete instructional environments in AR as far
            as the manipulation of real world objects is the target, a
            good example are maintenance support systems as the BMW
            augmented reality system. </p>
          <h3 style="font-weight: bold;"
id="section-Augmented+Reality+for+Learning-CollaborativeTaggingAndAnnotation">Collaborative




            Tagging and Annotation</h3>
          <p> First approaches on collaborative augmented reality can be
            found based on location-based environments where user can
            collaboratively annotate and tag real world objects and
            share this information with others. Furthermore first
            approaches also embed shared artifacts in games that or
            support the collaborative manipulation of 3D objects.<br>
          </p>
          <h2>Examples of Augmented Reality Applications<br>
          </h2>
          <p>The playlist below provides many examples of existing
            augmented reality applications. Let yourself inspire.<br>
          </p>
          <!--Embed YouTube-Video. Note: Use the "old" embed code. The iframe-Version won't work in the LAKER iOS app.-->
          <div class="media-right"> <object height="349" width="560"><param
value="http://www.youtube.com/p/64584AC6FD1EE047?version=3&amp;hl=de_DE&amp;fs=1"
                name="movie"><param value="true" name="allowFullScreen"><param
                value="always" name="allowscriptaccess"><embed
                allowfullscreen="true" allowscriptaccess="always"
                type="application/x-shockwave-flash"
                src="%3Cobject%20width=" 480"="" height="349"
                width="560"><param name="movie"
value="http://www.youtube.com/p/64584AC6FD1EE047?version=3&amp;hl=de_DE&amp;fs=1"><param
                name="allowFullScreen" value="true"><param
                name="allowscriptaccess" value="always"><embed
src="http://www.youtube.com/p/64584AC6FD1EE047?version=3&amp;hl=de_DE&amp;fs=1"
                type="application/x-shockwave-flash"
                allowscriptaccess="always" allowfullscreen="true"
                height="385" width="480"></object>
            <div class="caption">
              <div style="text-align: center;"> </div>
              <p style="text-align: left;">Augmented Reality playlist by
                consiliera <br>
                (Internetconnection required).</p>
            </div>
            <!--Div caption--> </div>
          <!--Div media right-->
          <p><br>
          </p>
          <!--############################################################################
End of content #########################################################################################################################################-->
        </div>
        <!--Div hyphenate-->
        <!--############################################################################
Start Footer ###########################################################################################################################################-->
        <!--Include footer data from inc/footer.html-->
        <div class="footer"> </div>
        <!--Div footer-->
        <!--############################################################################
End Footer #############################################################################################################################################-->
      </div>
    </div>
  </body>
</html>
